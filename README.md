\documentclass{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}

\begin{document}

\title{Обучение нейронной сети на наборе данных Wine}
\author{}
\date{}
\maketitle

\section{Введение}
В данном исследовании мы обучаем нейронную сеть для классификации вина на основе его химического состава. Для этого используется набор данных \texttt{Wine} из библиотеки \texttt{sklearn}, который включает 13 признаков для каждого образца вина. Задача заключается в классификации вина в одну из трёх категорий, используя искусственную нейронную сеть, построенную с помощью библиотеки \texttt{PyTorch}.

\section{Описание кода}
В процессе работы мы выполняем следующие шаги:

\subsection{Импорт библиотек и загрузка данных}
Для выполнения задачи мы импортируем необходимые библиотеки, такие как \texttt{torch} (для работы с нейронной сетью), \texttt{numpy} (для работы с данными), \texttt{matplotlib} (для построения графиков), а также \texttt{train\_test\_split} из \texttt{sklearn} для разделения данных на обучающие и тестовые выборки.

Затем мы загружаем набор данных и разделяем его на обучающую и тестовую выборки:

\subsection{Определение архитектуры нейронной сети}
Мы создаём класс \texttt{WineNet}, который реализует простую нейронную сеть с тремя слоями:

\texttt{forward} функция выполняет прямой проход через сеть:

\subsection{Обучение нейронной сети}
Для обучения модели используется алгоритм оптимизации \texttt{Adam} и функция потерь \texttt{CrossEntropyLoss}. В процессе обучения мы делим данные на мини-батчи, выполняем обратное распространение ошибки и обновляем параметры модели.

После каждой эпохи мы вычисляем точность на тестовых данных:

\subsection{Визуализация результатов}
После обучения модели мы строим графики, показывающие точность классификации в зависимости от количества скрытых нейронов в сети.

\section{Анализ графиков и выводы}

\subsection{График точности в зависимости от числа скрытых нейронов}
На графиках, отображающих точность модели на тестовых данных в зависимости от числа скрытых нейронов, можно увидеть, как изменение количества нейронов в скрытом слое влияет на качество классификации. Важно заметить, что точность модели стабилизируется после определённого числа нейронов, и увеличение их числа не приводит к значительному улучшению результатов.

\subsection{Средняя точность}
Для каждого количества скрытых нейронов на графике отображена средняя точность, вычисленная по всем эпохам обучения. Чёрные маркеры (\texttt{v}) показывают эту среднюю точность. Из графиков видно, что оптимальное количество скрытых нейронов варьируется в зависимости от конфигурации модели.

\subsection{Выводы}
1. Увеличение числа скрытых нейронов в некоторой степени улучшает точность модели, однако после достижения оптимального значения точность перестаёт существенно улучшаться.
2. Модель демонстрирует хорошую способность к классификации, достигая точности более 90\% на тестовых данных.
3. Рекомендуется выбирать количество скрытых нейронов в пределах оптимального диапазона для минимизации вычислительных затрат.

\end{document}
