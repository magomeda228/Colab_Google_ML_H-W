В рамках проведенного исследования были реализованы методы градиентного спуска, включая Linear Regression, Vanilla Gradient Descent, Stochastic Gradient Descent , Momentum Gradient Descent
Каждый из этих методов был дополнительно модифицирован для применения L2-регуляризации.
Оценка моделей проводилась с использованием различных функций потерь: MSE, MAE, Logcosh и Huber. Все методы были протестированы на датасете объявлений автомобилей на немецком сайте eBay.

В ходе экспериментов была выявлена оптимальная настройка гиперпараметров: метрика R² начала демонстрировать улучшения при значении регуляризационного параметра λ = 10⁻³ 
и tolerance = 0.1 для всех методов, при этом значение коэффициента µ в диапазоне от 10⁻⁴ до 10⁻¹ с шагом 10⁻¹ не оказывало значительного влияния на эффективность модели.

Были построены точечные графики зависимости производительности методов от значения λ и типа функции потерь без регуляризации. Из полученных результатов следует,
что метод Momentum демонстрирует наиболее быструю и стабильную реакцию на изменения значения λ независимо от выбранной функции потерь.

Для метода Стохастического градиентного спуска без L2-регуляризации была построена зависимость между количеством итераций и размером батча.
Графики показали линейное снижение статистических показателей по мере увеличения размера батча, что также сопровождалось увеличением времени обучения.

Результаты анализа позволили сделать вывод, что для данного датасета оптимальным вариантом является использование метода Momentum без применения L2-регуляризации,
что обеспечивает более быстрое и эффективное обучение модели с минимальными затратами времени.
