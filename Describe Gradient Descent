В рамках проведенного исследования были реализованы методы градиентного спуска, включая Linear Regression, Vanilla Gradient Descent, Stochastic Gradient Descent , Momentum Gradient Descent
Каждый из этих методов был дополнительно модифицирован для применения L2-регуляризации.
Оценка моделей проводилась с использованием различных функций потерь: MSE, MAE, Logcosh и Huber. Все методы были протестированы на датасете объявлений автомобилей на немецком сайте eBay.

В ходе экспериментов была выявлена оптимальная настройка гиперпараметров: метрика R² начала демонстрировать улучшения при значении регуляризационного параметра λ = 10⁻³ 
и tolerance = 0.1 для всех методов, при этом значение коэффициента µ в диапазоне от 10⁻⁴ до 10⁻¹ с шагом 10⁻¹ не оказывало значительного влияния на эффективность модели.

Были построены точечные графики зависимости производительности методов от значения λ и типа функции потерь без регуляризации. Из полученных результатов следует,
что метод Momentum демонстрирует наиболее быструю и стабильную реакцию на изменения значения λ независимо от выбранной функции потерь.

Для метода Стохастического градиентного спуска без L2-регуляризации была построена зависимость между количеством итераций и размером батча.
Графики показали линейное снижение статистических показателей по мере увеличения размера батча, что также сопровождалось увеличением времени обучения.

Результаты анализа позволили сделать вывод, что для данного датасета оптимальным вариантом является использование метода Momentum без применения L2-регуляризации,
что обеспечивает более быстрое и эффективное обучение модели с минимальными затратами времени.

In the framework of the conducted study, gradient descent methods, including Linear Regression, Vanilla Gradient Descent, Stochastic Gradient Descent, and Momentum Gradient Descent, were implemented.
Each of these methods was further modified to apply L2 regularization. Model evaluation was carried out using different loss functions: MSE, MAE, Logcosh, and Huber. 
All methods were tested on a dataset of car sales listings from the German eBay website.

During the experiments, the optimal hyperparameter settings were identified: the R² metric began to show improvements when the regularization parameter λ was set to 10⁻³ and tolerance to 0.1 for all methods.
The value of the coefficient µ in the range from 10⁻⁴ to 10⁻¹ with a step of 10⁻¹ had no significant effect on the model's performance.

Point graphs were created to analyze the performance of methods based on λ values and loss function types without regularization.
The results revealed that the Momentum method demonstrates the fastest and most stable response to changes in λ, regardless of the chosen loss function.

For the Stochastic Gradient Descent method without L2 regularization, a dependency between the number of iterations and batch size was established.
The graphs showed a linear decrease in statistical metrics as the batch size increased, accompanied by an increase in training time.

The analysis results led to the conclusion that for this dataset, the optimal choice is the use of the Momentum method without L2 regularization,
as it ensures faster and more efficient model training with minimal time costs.
