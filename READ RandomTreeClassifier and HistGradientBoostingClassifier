Введение
В данной работе исследовался датасет на фантастическую космиечскую катастрофу с подсчетом погибших в её результате
1. Анализ данных и корреляция признаков с целевой переменной
На основании исследования признаков выявлено, что такие переменные, как FoudCort, Cryosleep, и shappingMall, имеют лучшую корреляцию с целевой переменной. 
Это позволяет сосредоточиться на этих признаках для построения более качественной модели. Признаки с низкой корреляцией можно удалить, чтобы избежать увеличения шума в данных и уменьшить вероятность переобучения модели. 
(В ходе анализа было виявлено, что метрики log loss ставновят хуже с учетом удалёенных классов)

Анализ распределения целевой переменной показал, что большая часть транспортированных пассажиров прибыла с планеты Европа, а наименьшая – с Земли. 
Также распределение целевых классов относительно планет назначения продемонстрировало, что наиболее часто люди доставлялись на планету 55 Cancri e, а наименьшее количество прибыло на TRAPPIST-1-e.

Эти данные дают основания предполагать, что классы относительно сбалансированы, что положительно сказывается на обучении моделей. 
Однако для дополнительных проверок можно исследовать влияние классового дисбаланса на метрики.

2. Построение и настройка модели RandomForestClassifier
Для построения модели была выбрана Random Forest, поскольку этот алгоритм обеспечивает высокую устойчивость к шуму и переобучению. В процессе настройки модели были проведены следующие шаги:

Гиперпараметры:

Количество деревьев (n_estimators) установлено на 300 для уменьшения дисперсии и повышения устойчивости модели.
Максимальная глубина дерева (max_depth) была оптимизирована и установлена на 10. Это позволило уменьшить переобучение без значительных потерь в точности.
Минимальное количество объектов для разбиения узла (min_samples_split) и для листа (min_samples_leaf) оптимально установлены в диапазоне 2–5. 
Это ограничивает избыточное разбиение дерева и увеличивает его обобщающую способность.

Результаты на кросс-валидации:

Log_loss Mean Train: 0.4671, Log_loss Mean Valid: 0.5024
Accuracy Mean Train: 0.7788, Accuracy Mean Valid: 0.7508
F1 Mean Train: 0.7736, F1 Mean Valid: 0.7509
AUC ROC Mean Train: 0.8776, AUC ROC Mean Valid: 0.8344
AUC PR Mean Train: 0.8827, AUC PR Mean Valid: 0.8481
Модель показала высокие значения метрик AUC-ROC и AUC-PR, что свидетельствует о хорошей способности различать классы и поддерживать высокий уровень точности и полноты одновременно.

3. Построение и настройка модели HistGradientBoostingClassifier
В качестве альтернативы была исследована модель HistGradientBoostingClassifier. Основной целью было сравнить производительность этой модели с RandomForest.

Гиперпараметры:

Максимальное число итераций (max_iter) выбрано равным 35, так как дальнейшее увеличение приводило к росту log loss на валидации, что указывает на переобучение.
Максимальная глубина дерева (max_depth) установлена на 6, что позволило уменьшить колебания значений метрик.
Минимальное количество объектов для листа (min_samples_leaf) и максимальное количество листьев (max_leaf_nodes) выбраны равными 5 и 5 соответственно для обеспечения стабильности и устойчивости модели.
Результаты на кросс-валидации:

Log_loss Mean Train: 0.4715, Log_loss Mean Valid: 0.5038
Accuracy Mean Train: 0.7753, Accuracy Mean Valid: 0.7495
F1 Mean Train: 0.7692, F1 Mean Valid: 0.7501
AUC ROC Mean Train: 0.8297, AUC ROC Mean Valid: 0.8237
AUC PR Mean Train: 0.8400, AUC PR Mean Valid: 0.8343
Модель показала метрики ниже, чем у Random Forest, особенно по AUC ROC и AUC PR. Однако её преимуществом является более быстрое обучение на большом объеме данных.

4. Теоретические выкладки и рекомендации
AUC-ROC и AUC-PR:
AUC-ROC подходит для оценки общей способности модели различать классы. 
Однако для несбалансированных данных AUC-PR будет более информативной, поскольку делает акцент на точности и полноте для положительного класса. 
В данной работе Random Forest продемонстрировал более высокие значения обеих метрик, что подтверждает его лучшее качество предсказаний.

Log Loss:
Показатель log loss указывает, насколько хорошо модель предсказывает вероятности, близкие к истинным меткам. 
Более низкие значения log loss на Random Forest подтверждают, что модель более уверенно и точно предсказывает вероятность принадлежности к классу.

Сравнение моделей:
Random Forest лучше справился с задачей классификации, поскольку показал более высокие значения метрик и стабильное поведение на кросс-валидации. 
HistGradientBoostingClassifier оказался быстрее в обучении, но продемонстрировал признаки переобучения на больших значениях гиперпараметров и незначительно но ниже итоговые метрики.

Заключение
На основании проведённого анализа, оптимальной моделью для данного датасета является RandomForestClassifier с параметрами:

n_estimators=300, max_depth=10, min_samples_split=3, min_samples_leaf=3, max_features='sqrt'.
Эта модель показала лучшую производительность по ключевым метрикам и продемонстрировала высокую устойчивость к переобучению.
